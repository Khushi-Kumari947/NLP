{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiE/1M968Igf3XcaSkfrJg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khushi-Kumari947/NLP/blob/main/Stemming_lemmatizarion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mJMfV6e0sa5G"
      },
      "outputs": [],
      "source": [
        "#It is process of reducing inflections(modified word expressing different grammatical categories sucha s tense case,voice,aspect,person etc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Used extensively in information retrieval system"
      ],
      "metadata": {
        "id": "dKWOHV__supI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "mZ07E9RGyCJF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps=PorterStemmer()\n",
        "def stem_words(text):\n",
        "  return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "xcaXAJlwyQ0I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"walk walks walking walked\"\n",
        "stem_words(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2DfGIaGSydxb",
        "outputId": "4c1da31b-b881-45af-c2b2-6c319ae520a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk walk walk walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"The boys were running, jumping, and playing happily in the gardens.\"\n",
        "stem_words(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0HOlAU93yjw3",
        "outputId": "379bdb09-d7cf-4f9e-ba90-d02097c51da8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the boy were running, jumping, and play happili in the gardens.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Studies studying studied easily fairly running runner runs connection connected connecting.\"\n",
        "stem_words(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "E-nK65z2y42U",
        "outputId": "bf706fd9-dc5a-407f-b1ef-aef3a4ee7db2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'studi studi studi easili fairli run runner run connect connect connecting.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#since words are not a language word there fore we use lemmatization it give actual words as output\n",
        "#If you do not have to show output to users and want speed then use stemming as it's faster otherwise use lemmatization"
      ],
      "metadata": {
        "id": "gydtVUN5y_hr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization\n"
      ],
      "metadata": {
        "id": "2VgRDxVzwmrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVoqLXm_yNLs",
        "outputId": "b0f53aa3-0d62-4ec9-d9a5-ebfca3d94147"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')   # important (new NLTK versions)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPwL8c7Sx_kT",
        "outputId": "99600301-e3bd-4ae4-cb67-a19124be5371"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import SentiWordNetCorpusReader\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordNet_Lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "sentence=\"He was running and eating at the same time.he has bed habit of swimming after playing long hours in the sun\"\n",
        "\n",
        "punctuation=\"?:!.,;\"\n",
        "\n",
        "sentence_words=nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "  if word in punctuation:\n",
        "    sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:10}\".format(\"word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "  print(\"{0:20}{1:10}\".format(word,wordNet_Lemmatizer.lemmatize(word,pos='v')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlOMV8ddzgyC",
        "outputId": "cb32a3b7-a117-48de-d06b-44f5a751ba3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word                Lemma     \n",
            "He                  He        \n",
            "was                 be        \n",
            "running             run       \n",
            "and                 and       \n",
            "eating              eat       \n",
            "at                  at        \n",
            "the                 the       \n",
            "same                same      \n",
            "time.he             time.he   \n",
            "has                 have      \n",
            "bed                 bed       \n",
            "habit               habit     \n",
            "of                  of        \n",
            "swimming            swim      \n",
            "after               after     \n",
            "playing             play      \n",
            "long                long      \n",
            "hours               hours     \n",
            "in                  in        \n",
            "the                 the       \n",
            "sun                 sun       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4-iaWm8xzk-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}